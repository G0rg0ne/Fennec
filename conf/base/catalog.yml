# Here you can define all your datasets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://docs.kedro.org/en/stable/data/data_catalog.html

## mfcc method assessement

input_audio:
  type: partitions.PartitionedDataset
  dataset: fennec.datasets.customwavedataset.WaveDataSet
  path: data/01_raw/speaker_dataset
  filename_suffix: ".wav"

temporal_audio_figures:
  type: partitions.PartitionedDataset
  dataset: matplotlib.MatplotlibWriter
  path: data/02_intermediate/temporal_audio_figures
  filename_suffix: ".png"

librosa_spectrum_figures:
  type: partitions.PartitionedDataset
  dataset: matplotlib.MatplotlibWriter
  path: data/02_intermediate/librosa_spectrum_figures
  filename_suffix: ".png"

## Training and Evaluation Datasets

FSD50K_train_audio:
  type: partitions.PartitionedDataset
  dataset: fennec.datasets.customwavedataset.WaveDataSet
  path: data/01_raw/FSD50K.dev_audio
  filename_suffix: ".wav"
FSD50K_eval_audio:
  type: partitions.PartitionedDataset
  dataset: fennec.datasets.customwavedataset.WaveDataSet
  path: data/01_raw/FSD50K.eval_audio
  filename_suffix: ".wav"
GT_train_labels:
  type: pandas.CSVDataset
  filepath: "data/01_raw/FSD50K.ground_truth/dev.csv"
GT_eval_labels:
  type: pandas.CSVDataset
  filepath: "data/01_raw/FSD50K.ground_truth/eval.csv"
GT_vocab:
  type: pandas.CSVDataset
  filepath: "data/01_raw/FSD50K.ground_truth/vocabulary.csv"
  load_args:
    header: null
FSD50K_trained_model:
  type: fennec.datasets.torch_model.TorchModelDataset
  filepath: "data/06_models/FSD50K_model_.pth"

